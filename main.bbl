\begin{thebibliography}{10}

\bibitem{liu2021slake}
Bo~Liu, Li-Ming Zhan, Li~Xu, Lin Ma, Yan Yang, and Xiao-Ming Wu.
\newblock Slake: A semantically-labeled knowledge-enhanced dataset for medical
  visual question answering.
\newblock In {\em 2021 IEEE 18th International Symposium on Biomedical Imaging
  (ISBI)}, pages 1650--1654. IEEE, 2021.

\bibitem{Pelka2018RadiologyOI}
Obioma Pelka, Sven Koitka, Johannes R{\"u}ckert, Felix Nensa, and C.~Friedrich.
\newblock Radiology objects in context (roco): A multimodal image dataset.
\newblock In {\em CVII-STENT/LABELS@MICCAI}, 2018.

\bibitem{vaswani2017attention}
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
  Aidan~N Gomez, {\L}ukasz Kaiser, and Illia Polosukhin.
\newblock Attention is all you need.
\newblock {\em Advances in neural information processing systems}, 2017.

\bibitem{Dou_2022_CVPR}
Zi-Yi Dou, Yichong Xu, Zhe Gan, Jianfeng Wang, Shuohang Wang, Lijuan Wang,
  Chenguang Zhu, Pengchuan Zhang, Lu~Yuan, Nanyun Peng, Zicheng Liu, and
  Michael Zeng.
\newblock An empirical study of training end-to-end vision-and-language
  transformers.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition (CVPR)}, pages 18166--18176, June 2022.

\bibitem{liu2022dpt}
Yuhang Liu, Wei Wei, Daowan Peng, and Feida Zhu.
\newblock Declaration-based prompt tuning for visual question answering.
\newblock In {\em Proceedings of the Thirty-first International Joint
  Conference on Artificial Intelligence, {IJCAI-22}}, 2022.

\bibitem{chen2022c}
Zhang Chen, Zhiqiang Tian, Jihua Zhu, Ce~Li, and Shaoyi Du.
\newblock C-cam: Causal cam for weakly supervised semantic segmentation on
  medical image.
\newblock In {\em Proceedings of the IEEE/CVF Conference on Computer Vision and
  Pattern Recognition}, pages 11676--11685, 2022.

\bibitem{kavur2021chaos}
A~Emre Kavur, N~Sinem Gezer, Mustafa Bar{\i}{\c{s}}, Sinem Aslan, Pierre-Henri
  Conze, Vladimir Groza, Duc~Duy Pham, Soumick Chatterjee, Philipp Ernst,
  Sava{\c{s}} {\"O}zkan, et~al.
\newblock Chaos challenge-combined (ct-mr) healthy abdominal organ
  segmentation.
\newblock {\em Medical Image Analysis}, page 101950, 2021.

\bibitem{DBLP:journals/corr/abs-2003-10286}
Xuehai He, Yichen Zhang, Luntian Mou, Eric~P. Xing, and Pengtao Xie.
\newblock Pathvqa: 30000+ questions for medical visual question answering.
\newblock {\em CoRR}, 2020.

\bibitem{lau2018dataset}
Jason~J Lau, Soumya Gayen, Asma Ben~Abacha, and Dina Demner-Fushman.
\newblock A dataset of clinically generated visual questions and answers about
  radiology images.
\newblock {\em Scientific data}, pages 1--10, 2018.

\bibitem{ben2019vqa}
Asma Ben~Abacha, Sadid~A Hasan, Vivek~V Datla, Dina Demner-Fushman, and Henning
  M{\"u}ller.
\newblock Vqa-med: Overview of the medical visual question answering task at
  imageclef 2019.
\newblock In {\em Proceedings of CLEF (Conference and Labs of the Evaluation
  Forum) 2019 Working Notes}, 2019.

\bibitem{chen2022align}
Zhihong Chen, Guanbin Li, and Xiang Wan.
\newblock Align, reason and learn: Enhancing medical vision-and-language
  pre-training with knowledge.
\newblock In {\em Proceedings of the 30th ACM International Conference on
  Multimedia}, pages 5152--5161, 2022.

\bibitem{chen2022multi}
Zhihong Chen, Yuhao Du, Jinpeng Hu, Yang Liu, Guanbin Li, Xiang Wan, and
  Tsung-Hui Chang.
\newblock Multi-modal masked autoencoders for medical vision-and-language
  pre-training.
\newblock In {\em Medical Image Computing and Computer Assisted
  Intervention--MICCAI 2022: 25th International Conference, Singapore,
  September 18--22, 2022, Proceedings, Part V}, pages 679--689. Springer, 2022.

\bibitem{li2020oscar}
Xiujun Li, Xi~Yin, Chunyuan Li, Pengchuan Zhang, Xiaowei Hu, Lei Zhang, Lijuan
  Wang, Houdong Hu, Li~Dong, Furu Wei, et~al.
\newblock Oscar: Object-semantics aligned pre-training for vision-language
  tasks.
\newblock In {\em Computer Vision--ECCV 2020: 16th European Conference,
  Glasgow, UK, August 23--28, 2020, Proceedings, Part XXX 16}, pages 121--137.
  Springer, 2020.

\bibitem{li2021align}
Junnan Li, Ramprasaath Selvaraju, Akhilesh Gotmare, Shafiq Joty, Caiming Xiong,
  and Steven Chu~Hong Hoi.
\newblock Align before fuse: Vision and language representation learning with
  momentum distillation.
\newblock {\em Advances in neural information processing systems}, pages
  9694--9705, 2021.

\bibitem{li2022blip}
Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi.
\newblock Blip: Bootstrapping language-image pre-training for unified
  vision-language understanding and generation.
\newblock In {\em International Conference on Machine Learning}, pages
  12888--12900. PMLR, 2022.

\bibitem{lin2014microsoft}
Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva
  Ramanan, Piotr Doll{\'a}r, and C~Lawrence Zitnick.
\newblock Microsoft coco: Common objects in context.
\newblock In {\em Computer Vision--ECCV 2014: 13th European Conference, Zurich,
  Switzerland, September 6-12, 2014, Proceedings, Part V 13}, pages 740--755.
  Springer, 2014.

\bibitem{subramanian-2020-medicat}
Sachin Mehta Ben Bogin Madeleine van Zuylen Sravanthi Parasa Sameer Singh
  Matt~Gardner Sanjay~Subramanian, Lucy Lu~Wang and Hannaneh Hajishirzi.
\newblock {MedICaT: A Dataset of Medical Images, Captions, and Textual
  References}.
\newblock In {\em Findings of EMNLP}, 2020.

\bibitem{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In {\em Medical Image Computing and Computer-Assisted
  Intervention--MICCAI 2015: 18th International Conference, Munich, Germany,
  October 5-9, 2015, Proceedings, Part III 18}, pages 234--241. Springer, 2015.

\bibitem{zhang2021vinvl}
Pengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei Yang, Lei Zhang, Lijuan Wang,
  Yejin Choi, and Jianfeng Gao.
\newblock Vinvl: Revisiting visual representations in vision-language models.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition}, pages 5579--5588, 2021.

\bibitem{eslami-etal-2023-pubmedclip}
Sedigheh Eslami, Christoph Meinel, and Gerard de~Melo.
\newblock {P}ub{M}ed{CLIP}: How much does {CLIP} benefit visual question
  answering in the medical domain?
\newblock In {\em Findings of the Association for Computational Linguistics:
  EACL 2023}, pages 1181--1193. Association for Computational Linguistics,
  2023.

\bibitem{rumelhart1985learning}
David~E Rumelhart, Geoffrey~E Hinton, and Ronald~J Williams.
\newblock Learning internal representations by error propagation.
\newblock Technical report, California Univ San Diego La Jolla Inst for
  Cognitive Science, 1985.

\bibitem{dosovitskiy2020vit}
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
  Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
  Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
\newblock An image is worth 16x16 words: Transformers for image recognition at
  scale.
\newblock {\em ICLR}, 2021.

\bibitem{Liu_2021_ICCV}
Ze~Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and
  Baining Guo.
\newblock Swin transformer: Hierarchical vision transformer using shifted
  windows.
\newblock In {\em Proceedings of the IEEE/CVF International Conference on
  Computer Vision (ICCV)}, pages 10012--10022, October 2021.

\bibitem{devlin-etal-2019-bert}
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
\newblock {BERT}: Pre-training of deep bidirectional transformers for language
  understanding.
\newblock In {\em Proceedings of the 2019 Conference of the North {A}merican
  Chapter of the Association for Computational Linguistics: Human Language
  Technologies, Volume 1 (Long and Short Papers)}, pages 4171--4186,
  Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

\bibitem{brown2020language}
Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared~D Kaplan, Prafulla
  Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
  et~al.
\newblock Language models are few-shot learners.
\newblock {\em Advances in neural information processing systems}, pages
  1877--1901, 2020.

\bibitem{tan2019lxmert}
Hao Tan and Mohit Bansal.
\newblock Lxmert: Learning cross-modality encoder representations from
  transformers.
\newblock In {\em EMNLP/IJCNLP (1)}, pages 5099--5110. Association for
  Computational Linguistics, 2019.

\bibitem{lu2019vilbert}
Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee.
\newblock Vilbert: Pretraining task-agnostic visiolinguistic representations
  for vision-and-language tasks.
\newblock {\em Advances in neural information processing systems}, 2019.

\bibitem{VQA}
Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
  C.~Lawrence Zitnick, and Devi Parikh.
\newblock {VQA}: {V}isual {Q}uestion {A}nswering.
\newblock In {\em International Conference on Computer Vision (ICCV)}, 2015.

\bibitem{balanced_binary_vqa}
Peng Zhang, Yash Goyal, Douglas Summers{-}Stay, Dhruv Batra, and Devi Parikh.
\newblock {Y}in and {Y}ang: Balancing and answering binary visual questions.
\newblock In {\em Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2016.

\bibitem{balanced_vqa_v2}
Yash Goyal, Tejas Khot, Douglas Summers{-}Stay, Dhruv Batra, and Devi Parikh.
\newblock Making the {V} in {VQA} matter: Elevating the role of image
  understanding in {V}isual {Q}uestion {A}nswering.
\newblock In {\em Conference on Computer Vision and Pattern Recognition
  (CVPR)}, 2017.

\bibitem{chen2023towards}
Zhihong Chen, Shizhe Diao, Benyou Wang, Guanbin Li, and Xiang Wan.
\newblock Towards unifying medical vision-and-language pre-training via soft
  prompts.
\newblock {\em arXiv preprint arXiv:2302.08958}, 2023.

\bibitem{moon2022multi}
Jong~Hak Moon, Hyungyung Lee, Woncheol Shin, Young-Hak Kim, and Edward Choi.
\newblock Multi-modal understanding and generation for medical images and text
  via vision-language pre-training.
\newblock {\em IEEE Journal of Biomedical and Health Informatics}, pages
  6070--6080, 2022.

\bibitem{khare2021mmbert}
Yash Khare, Viraj Bagal, Minesh Mathew, Adithi Devi, U~Deva Priyakumar, and
  CV~Jawahar.
\newblock Mmbert: Multimodal bert pretraining for improved medical vqa.
\newblock In {\em 2021 IEEE 18th International Symposium on Biomedical Imaging
  (ISBI)}, pages 1033--1036. IEEE, 2021.

\bibitem{nguyen2019overcoming}
Binh~D Nguyen, Thanh-Toan Do, Binh~X Nguyen, Tuong Do, Erman Tjiputra, and
  Quang~D Tran.
\newblock Overcoming data limitation in medical visual question answering.
\newblock In {\em Medical Image Computing and Computer Assisted
  Intervention--MICCAI 2019: 22nd International Conference, Shenzhen, China,
  October 13--17, 2019, Proceedings, Part IV 22}, pages 522--530. Springer,
  2019.

\bibitem{do2021multiple}
Tuong Do, Binh~X Nguyen, Erman Tjiputra, Minh Tran, Quang~D Tran, and Anh
  Nguyen.
\newblock Multiple meta-model quantifying for medical visual question
  answering.
\newblock In {\em Medical Image Computing and Computer Assisted
  Intervention--MICCAI 2021: 24th International Conference, Strasbourg, France,
  September 27--October 1, 2021, Proceedings, Part V 24}, pages 64--74.
  Springer, 2021.

\bibitem{gong2022vqamix}
Haifan Gong, Guanqi Chen, Mingzhi Mao, Zhen Li, and Guanbin Li.
\newblock Vqamix: Conditional triplet mixup for medical visual question
  answering.
\newblock {\em IEEE Transactions on Medical Imaging}, pages 3332--3343, 2022.

\bibitem{zhang2022type}
Anda Zhang, Wei Tao, Ziyan Li, Haofen Wang, and Wenqiang Zhang.
\newblock Type-aware medical visual question answering.
\newblock In {\em ICASSP 2022-2022 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP)}, pages 4838--4842. IEEE, 2022.

\bibitem{yan2022clinical}
Bin Yan and Mingtao Pei.
\newblock Clinical-bert: Vision-language pre-training for radiograph diagnosis
  and reports generation.
\newblock In {\em Proceedings of the AAAI Conference on Artificial
  Intelligence}, pages 2982--2990, 2022.

\bibitem{Wang2022MedCLIPCL}
Zifeng Wang, Zhenbang Wu, Dinesh Agarwal, and Jimeng Sun.
\newblock Medclip: Contrastive learning from unpaired medical images and text.
\newblock {\em ArXiv}, 2022.

\bibitem{radford2021learning}
Alec Radford, Jong~Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
  Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
  et~al.
\newblock Learning transferable visual models from natural language
  supervision.
\newblock In {\em International conference on machine learning}, pages
  8748--8763. PMLR, 2021.

\bibitem{He_2016_CVPR}
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
\newblock Deep residual learning for image recognition.
\newblock In {\em Proceedings of the IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR)}, June 2016.

\bibitem{zhuang-etal-2021-robustly}
Liu Zhuang, Lin Wayne, Shi Ya, and Zhao Jun.
\newblock A robustly optimized {BERT} pre-training approach with post-training.
\newblock In {\em Proceedings of the 20th Chinese National Conference on
  Computational Linguistics}, pages 1218--1227, 2021.

\bibitem{kingma2015adam}
Diederik~P Kingma and Jimmy Ba.
\newblock {Adam: A Method for Stochastic Optimization}.
\newblock In {\em Proceedings of International Conference on Representation
  Learning}, 2015.

\bibitem{cubuk2020randaugment}
Ekin~D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc~V Le.
\newblock Randaugment: Practical automated data augmentation with a reduced
  search space.
\newblock In {\em Proceedings of the IEEE/CVF conference on computer vision and
  pattern recognition workshops}, pages 702--703, 2020.

\bibitem{paszke2017automatic}
Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary
  DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer.
\newblock Automatic differentiation in pytorch.
\newblock 2017.

\bibitem{wolf2019huggingface}
Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue,
  Anthony Moi, Pierric Cistac, Tim Rault, R{\'e}mi Louf, Morgan Funtowicz,
  et~al.
\newblock Huggingface's transformers: State-of-the-art natural language
  processing.
\newblock {\em arXiv preprint arXiv:1910.03771}, 2019.

\bibitem{houlsby2019parameter}
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin
  De~Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly.
\newblock Parameter-efficient transfer learning for nlp.
\newblock In {\em International Conference on Machine Learning}, pages
  2790--2799. PMLR, 2019.

\end{thebibliography}
