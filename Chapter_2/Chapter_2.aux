\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related Work}{7}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:ch2}{{2}{7}{}{}{}}
\citation{vaswani2017attention}
\citation{rumelhart1985learning}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Transformer Attention}{8}{}\protected@file@percent }
\newlabel{transformer}{{2.1}{8}{}{}{}}
\citation{vaswani2017attention}
\citation{vaswani2017attention}
\citation{vaswani2017attention}
\citation{vaswani2017attention}
\citation{dosovitskiy2020vit}
\citation{Liu_2021_ICCV}
\newlabel{eq:attention}{{2.1}{9}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Vision Transformer}{9}{}\protected@file@percent }
\newlabel{vit}{{2.1.1}{9}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Transformer architecture \cite  {vaswani2017attention}}}{10}{}\protected@file@percent }
\newlabel{fig:transformer}{{2.1}{10}{}{}{}}
\citation{devlin-etal-2019-bert}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Attention mechanisms \cite  {vaswani2017attention}: (a) Scaled dot-product attention, (b) Multi-head attention}}{11}{}\protected@file@percent }
\newlabel{fig:attention}{{2.2}{11}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Language Transformer}{11}{}\protected@file@percent }
\newlabel{language transformer}{{2.1.2}{11}{}{}{}}
\citation{vaswani2017attention}
\citation{brown2020language}
\citation{Dou_2022_CVPR}
\citation{li2020oscar}
\citation{li2022blip}
\citation{li2021align}
\citation{tan2019lxmert}
\citation{lu2019vilbert}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Vision and Language Pre-Training}{12}{}\protected@file@percent }
\newlabel{vlp}{{2.2}{12}{}{}{}}
\citation{Dou_2022_CVPR}
\citation{Dou_2022_CVPR}
\citation{Dou_2022_CVPR}
\citation{Dou_2022_CVPR}
\citation{Dou_2022_CVPR}
\citation{Dou_2022_CVPR}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Masked language modeling \cite  {Dou_2022_CVPR}}}{13}{}\protected@file@percent }
\newlabel{fig:mlm}{{2.3}{13}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Image-text matching \cite  {Dou_2022_CVPR} involves determining whether an image and its corresponding caption are a match or not. The top image represents a positive pair, indicating a matching image and caption. On the other hand, the bottom image represents a negative pair, indicating a non-matching image and caption.}}{14}{}\protected@file@percent }
\newlabel{fig:itm}{{2.4}{14}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces  The image-text matching head \cite  {Dou_2022_CVPR} consists of two fully connected layers in its architecture.}}{14}{}\protected@file@percent }
\newlabel{fig:itmhead}{{2.5}{14}{}{}{}}
\citation{VQA}
\citation{balanced_binary_vqa}
\citation{balanced_vqa_v2}
\citation{liu2022dpt}
\citation{liu2022dpt}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Visual Question Answering}{15}{}\protected@file@percent }
\newlabel{vqa}{{2.3}{15}{}{}{}}
\citation{liu2021slake}
\citation{DBLP:journals/corr/abs-2003-10286}
\citation{lau2018dataset}
\citation{ben2019vqa}
\citation{chen2022align}
\citation{chen2023towards}
\citation{moon2022multi}
\citation{chen2022multi}
\citation{khare2021mmbert}
\citation{liu2021slake}
\citation{nguyen2019overcoming}
\citation{do2021multiple}
\citation{gong2022vqamix}
\citation{zhang2022type}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Visual question answering \cite  {liu2022dpt} is a task in which a model takes images and corresponding questions as input and generates accurate answers as output. }}{16}{}\protected@file@percent }
\newlabel{fig:vqa}{{2.6}{16}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Medical Visual Question Answering}{16}{}\protected@file@percent }
\newlabel{medvqa}{{2.4}{16}{}{}{}}
\@setckpt{Chapter_2/Chapter_2}{
\setcounter{page}{17}
\setcounter{equation}{1}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{6}
\setcounter{table}{0}
\setcounter{float@type}{4}
\setcounter{caption@flags}{2}
\setcounter{continuedfloat}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{parentequation}{0}
}
