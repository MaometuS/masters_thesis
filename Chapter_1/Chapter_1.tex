\chapter{Introduction}
\label{chapter:intro}

%iad_field
In our modern times when we strive to automate every menial task that was resolved by human labor, one of the fields that have been the most important is the industrial manufacturing processes. In improving the process of production, the key point is to ensure the reliability of the process and the quality of the produce. Throughout the recent years, the use of Machine Learning algorithms, specifically Computer Vision models, have showed to be a powerful tool in detecting the defects(called anomalies in the field of machine learning)\cite{iad_survey}. Therefore, a new field: Industrial Anomaly Detection\cite{iad_survey} was formed, which focuses on researching and developing efficient computer vision models in the field. There are generally two types of architectures in the industrial anomaly detection models: feature embedding based architectures\cite{patchcore} and reconstruction based architectures\cite{realnet}. Most contemporary models are trained without supervision\cite{uiad_survey} and they, due to the lack of large scale image dataset of industrial objects\cite{mvtecad} and the unbalanced nature of available datasets towards nominal samples, rely on the feature space of a pre-trained model\cite{bergman2020deepnearestneighboranomaly}\cite{pre_trained}\cite{pre_trained_iad}.

%iad_arch
The training process depends on the architecture of the model. In feature-embedding\cite{patchcore} types of architectures, usually the training process involves performing a feature extractions\cite{pre_trained} and saving them with various modifications\cite{pre_trained_iad}. Thereafter, during inference same feature extraction applied to the image being inferred followed by various statistical methods used to calculate the anomaly score of the sample\cite{patchcore}. An example for the feature embedding architecture can be a model PatchCore\cite{patchcore}, which saves nominal features in the memory bank after applying neighborhood aggregation and utilized k-nearest neighbor method\cite{knn} to calculate an anomaly score\cite{auroc}. In reconstruction based methods\cite{realnet}, autoencoder models\cite{autoencoder} is trained either on the features extracted by the pre-trained model or the pre-trained model is used as an encoder inside the autoencoder. For example, in the RealNet\cite{realnet} model multiple autoencoders are trained on the layers of the feature extractor model. The architecture of the commonly used PatchCore model can be seen on the figure \ref{fig:patchcore}

\begin{figure}[t]
\begin{center}
\includegraphics[width=1.0\linewidth]{Chapter_1/patchcore.png}
\end{center}
\caption{Architecture of the PatchCore\cite{patchcore} model where one of the main components is the pre-trained feature extractor, here referred to as "Pretrained Encoder"}
\label{fig:patchcore}
\end{figure}

In this paper we hypothesize that using ImageNet\cite{imagenet} pre-trained models as feature extractors\cite{pre_trained} in industrial anomaly detection models\cite{pre_trained_iad} can be a potential bottleneck of performance due to the generalized nature of the dataset. There is a large representation mismatch between ImageNet which contains a large quantity of natural samples whereas the IAD\cite{iad_survey} requires features which represent industrial objects more accurately. Our hypothesis implies that most if not all existing models could benefit from a more specialized feature space which is extracted from datasets with focus on more industrial settings rather than being general or having natural samples.

In order to address this issue the thesis proposes to generate a feature space that would represent the type of data that is used in industrial anomaly detection tasks. In order to accomplish this task, we propose extracting an industrial setting sub-datasets from a large multi-purpose dataset\cite{yfcc100m}\cite{laion400m}\cite{laion5b}, followed by performing a training on the extracted dataset to have a feature extractor. Throughout this process it is important to choose appropriate dataset to extract from, a proper self supervised learning method\cite{self_supervised_survey} and an accurate extraction method. All three parts of the pipeline are important and have to be a deliberate choice, however the most important part and the defining factor for the quality of the extracted features is the extraction method.

In this thesis we opted to utilize a ResNet50 model trained on the dataset curated by hand. However, in this thesis, we will also be discussing other possible options for industrial image extractors. Due to the unlabeled nature of the extracted dataset by the method of our choice, this work will use the DINO\cite{dino} unsupervised learning method on all experiments as a feature learning tool. The choice is also motivated by the capability of DINO to train both Vision Transformer and Convolution based networks.

To evaluate the accuracy of different feature spaces against each other, we use PatchCore\cite{patchcore} as the main industrial anomaly detection model\cite{iad_survey}. All pre-trained models are to be used as backbones\cite{pre_trained} for the model and evaluated\cite{auroc} on the accuracy of the model on MVTechAD\cite{mvtecad} dataset. Firstly, we perform experiments on ViT\cite{vit} based backbones because Vision Transformers\cite{vit} are more robust for self-supervised learning method\cite{self_supervised_survey} which we utilize in this work. However, with further experiments we show that convolution based models\cite{lenet} are much better fit for the task of industrial anomaly detection\cite{iad_survey}. And lastly we provide comparisons between random extraction of images, selective extraction of images and state-of-the-art backbone when used with PatchCore model.

In this introductory chapter we unveiled the field of Industrial Anomaly Detection\cite{iad_survey} and the potential accuracy bottleneck present in most applications. In the Chapter~\ref{chapter:ch2} the Related Work will be thoroughly discussed, namely the topics will be Vision Transformers\cite{vit}, Residual Networks\cite{resnet}, Wide Residual Networks\cite{wideresnet} and their architectural differences. Moreover, we will further discuss PatchCore\cite{patchcore} and RealNet\cite{realnet} models and their use of pre-trained networks\cite{pre_trained}. Chapter~\ref{chapter:ch3} will focus on the possible bottleneck of using ImageNet\cite{imagenet} pre-trained networks as feature extractors and the solutions that can be engaged to address the issue. Chapter~\ref{chapter:ch4} contains the demonstration of the potential of the proposed solution through empirical evidence, conducted series of experiments will be explained in detail. And lastly, Chapter~\ref{chapter:ch5} will serve as a conclusion where we will summarize the results of this work. Moreover, it the last chapter, we will suggest multiple methods of feature space generation that can be explored in further research.