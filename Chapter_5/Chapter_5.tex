\chapter{Conclusions and Future Improvements}
\label{chapter:ch5}

\section{Conclusions}

This thesis focused on the analyzing the usage of pre-trained feature extractors in industrial anomaly detection\cite{iad_survey}\cite{uiad_survey}\cite{pre_trained_iad} and possibly ways of improving the accuracy of models by addressing the hypothesized bottleneck. We postulated that the generality of ImageNet dataset\cite{imagenet}, on which most predominantly utilized pre-trained extractors trained on, could generate non-ideal features for the use in industrial settings. The postulation was motivated by the fact that ImageNet, in the considerable amount, consists of images that do not represent the industrial field nor do they relate to images that are commonly used in industrial tasks like MVTechAD\cite{mvtecad}. 

We presented two methods for addressing the proposed issue: selective image extraction by using a CNN\cite{lenet} bi-class classifier, selecteive image extraction with the help of Large Language Models(LLM)\cite{llm_survey}\cite{gpt3} and Vision Language Models(VLM)\cite{vlm_survey}\cite{clip}. First method relies on bi-class CNN model that was trained on pre-constructed dataset with labels "industrial" and "non-industrial". Second method is based on the generation of descriptors using an LLM and filtering images by a CLIP\cite{clip} cosine similarity score between the descriptors and samples. Both methods were applied to a large multi purpose dataset in order to generate a specialized dataset for industrial tasks. Throughout the work in this thesis both supervised and self-supervised learning methods\cite{self_supervised_survey}\cite{dino} were engaged to achieve feature learning.

After extensive series of experiments on the feature learned from extracted datasets, it was determined that the feature space of WideResNet\cite{wideresnet}, which is commonly used in contemporary industrial anomaly detection models\cite{patchcore}\cite{pre_trained_iad}, is surprisingly efficient and extremely resilient to scrutiny. Althoug we were successful in improving the performance in some categories of objects in the dataset MVTechAD, all attempts to outperform the state of the art pre-trained feature extractor in all categories were met with failure. However, we learned that the contents of the dataset from which features are learned from is very important.

In conclusion, through experiments we determined that ImageNet based feature spaces are surprisingly efficient for industrial anomaly detection tasks, despite the general nature of ImageNet dataset. Performance increase through improved feature space could still be achievable, but methods presented in this were proven to be inefficient in this task.

\section{Future Improvements}

As was stated in the previous section, we were able to archive higher than sota accuracies in several categories while under performing on others. This discovery demonstrates the feasibility of achieving overhead on the performance of the sota feature extractor. As per the selective extraction, designing the extraction pipeline more meticulously might show a promising performance. Another method to achieve an extraction of a high quality industrial dataset might be the usage of LLMs on large scale, CLIP labeled datasets like LAION5B\cite{laion5b}. For the dataset extraction methods, in our opinion, these seem to be the all possible options as of now.

For the feature space based improvements of industrial anomaly detection models, an approach used in the IAD model RealNet\cite{realnet} could be extended and utilized as a component in pipeline of other models. The approach is the feature selection during training time which consists of building a large scale general feature space with high variety in the features, and performing the selection of features that are best for the specific use case during training time\cite{realnet}. However, development as testing of such hypothesis might prove to be both very time and cost inefficient.

Lastly, introduction of anomalous features into a features space during pre-training as as the IAD models GLASS\cite{glass} and RealNet\cite{realnet} do during train time, could bring performance improvements. This could be achieved fine-tuning of the pre-trained feature extractor with artificially generated anomalies.

We believe that all the presented methods pose a potential for an improvement and needs further extensive investigation.